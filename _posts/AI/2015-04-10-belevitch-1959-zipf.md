---
layout: post
category: AI
title: On the Statistical Laws of Linguistic Distributions
tagline:  Paper 
date: 2015-04-10
tags: [Zipf,PowerLaw,NLP]
published: false
---
{% include JB/setup %}

{% include custom/paper_review %}


Belevitch 1959

Argument shows that rank proportional to frequency (to a power) is a 
characteristic of most roughly linear distributions.  


Perhaps truncated log-normal is an even better match to actual word frequencies, 
rather than defining distribution in terms of Zipf relationship.

i.e. fix up the distribution to be the tail of a log-normal distribution, and see what happens

But why use a tail?  Isn't there a distribution where the whole thing is relevant (exponential?)

