---
layout: post
category: AI
title: 1 Billion Words for NLP
tagline: Presentation link
date: 2015-01-15
tags: [NLP,NeuralNetworks,Presentation]
published: true
---
{% include JB/setup %}

This talk was a preview of the Theano code (and the ideas behind 
word-embedding) that I plan to release soon (i.e. so that people can
play around with it before May-2015).

A working solution to the Billion Word Imputation challenge will *hopefully*
appear on [my GitHub account](http://github.com/mdda) 
shortly (was planned for 15-Jan-2015, still in process).

### Research Links

Key papers to have a look at :

  * [GloVe - Global Vectors for Word Representation - (Pennington, Socher, Manning 2014)](http://nlp.stanford.edu/pubs/glove.pdf), 
    which I wrote up [here](/ai/2014/10/13/GloVe/).
    
  * [Mikolov 2012](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) and 
    the [Word2Vec code](https://code.google.com/p/word2vec/), and 
    also [a nice Python version, with interesting optimization talk](http://radimrehurek.com/gensim/index.html).

  * [Mnih approach](/ai/2014/10/12/noise-contrastive-estimation/)


### Presentation Link

I recently gave a <strong><a href="http://redcatlabs.com/2015-01-15_Presentation-PyDataSG/" target="_blank">presentation about this project</a></strong> 
to the [Singapore PyData MeetUp Group](https://www.facebook.com/events/994351117258134/).

![Presentation Screenshot]({{ site.url }}/assets/img/2015-01-15_Presentation-PyDataSG_600x390.png)

If there are any questions about the presentation, please ask below, or via the MeetUp group.

![Presentation Content Example]({{ site.url }}/assets/img/2015-01-15_Presentation-PyDataSG_2_600x390.png)
