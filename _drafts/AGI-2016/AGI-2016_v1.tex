% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%  
\documentclass[citeauthoryear]{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
%
\begin{document}
%
\frontmatter          % for the preliminaries
%
\pagestyle{headings}  % switches on printing of running heads
\addtocmark{Consciousness and the Social Machine} % additional mark in the TOC
%
\mainmatter              % start of the contributions
%
\title{Consciousness and the Social Machine}
%
\titlerunning{Consciousness and the Social Machine}  % abbreviated title (for running head)
%                                                      also used for the TOC unless
%                                                      \toctitle is used
%
%\author{Martin Andrews\inst{1}}
\author{Martin Andrews}
%
\authorrunning{Martin Andrews} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
\tocauthor{Martin Andrews}
%
\institute{Red Cat Labs, Singapore\\
\email{Martin.Andrews@RedCatLabs.com}\\ 
%WWW home page: \texttt{http://RedCatLabs.com/}
}

\maketitle              % typeset the title of the contribution

%%%% using at least 70 and at most 150 words. It will be set in 9-point
\begin{abstract}

One \emph{known unknown} in the pursuit of AGI is how consciousness can be incorporated
in a machine's design.  
%
Graziano and Kastner's Attention Schema theory (\cite{GrazianoKastner})
describes a mechanism of human consciousness 
that potentially allows the `hard problem of consciousness' for machines 
to be approached with an engineering mindset.
%
This short note summarizes the Attention Schema theory, 
puts it in an up-to-date machine learning context, 
and discusses some practical issues of conscious machines.

\keywords{consciousness, attention schema, awareness, chatbots}
\end{abstract}
%

%\section{Overview}
%
%Short "technical communications", with a limit of 4 pages, 
%summarizing results and ideas of interest to the AGI audience, 
%including : 
%  reports about recent publications, 
%  position papers, and 
%  preliminary results.
%
%Appropriate topics for contributed papers include, but are not restricted to:
%  Creativity
%  Knowledge Representation for General Intelligence
%  Learning, and Learning Theory
%  Natural Language Understanding
%  Neural-Symbolic Processing
%**Philosophy of AGI
%  Reinforcement Learning
%
%Submission deadline moved from 25-march-2016 to 1-apr-2016
%  :: http://agi-conf.org/2015/call-for-papers/

\section{Introduction}

The essence of Attention Schema theory is that ``awareness is a description of 
attention''\footnote{Further background for the theory, 
and comparisons to a number of contrasting theories of consciousness,
are presented in Graziano's \cite{graziano2013consciousness} book.}.
For concreteness, we can describe how a brain can be `aware' of an apple,
using several functional steps :

\begin{description}
\item[Input] - pixels representing the shape of the apple itself
\item[Attention] - identifying the outline of recognisable objects in the image 
\item[Recognition] - after some processing, activating an `apple' label
\item[Context] - every new input can be embellished with additional context (previous experiences, for instance)
\item[Attention Schema] - a model of the brain's pattern of attention to represent what it is currently aware of
\item[Responsiveness] - querying the Attention Schema to respond to questions, or direct further actions, etc
\end{description}

Of course, the step above that is currently unknown is the form of the Attention Schema model.  
Importantly, though, many of this model's properties can be deduced from considering 
what human brains require for social interaction.

As a social animal, humans have gained significant adaptive advantage from 
being able to model the attention and motivation of other humans (an ``Other Model'').  
%
And this mechanism can be applied (at an even higher resolution) in 
modelling the state of the self (the ``Self Model''), which gives rise to another adaptive advantage
in higher-order planning, for instance. 
%

%Just as human brains continually build models of other's 

%The theory suggests that consciousness is no bizarre byproduct -- it's a tool for regulating information in the brain.

%Graziano still writing about his `new theory' to promote it in popular press.


Noteably, this Self Model does not create awareness as an emergent property of 
having `enough' internal information, nor have any mystical quality.  
%
The Self Model here need not possess any information about how it was built, 
nor its actual physicality.  
%
The brain/machine is not even in a position to report that it has internal models, 
or that it's processing information at all.
%
If its programmers gave the machine (as a whole) a preference for discovery (for instance),
the Self Model would simply recognise and report its inquistiveness, just as it 
could identify inquistiveness in Others.

%One key differentiating factor from other theories (compared to LIDA () for instance)
%
%Doesn't need full canvas of inputs (compare to LIDA, for instance)
%  The LIDA Model as a Foundational Architecture for AGI - http://ccrg.cs.memphis.edu/assets/papers/2012/LIDA-Foundational%20Architecture%20for%20AGI.pdf




\section{Current Components}

In recent years, neural network methods have begun to bear fruit (after years
of painstaking work - for a review see Schmidhuber \cite{SchmidhuberOverview}).
%
Under the broad heading of ``Deep Learning'', these techniques have yielded 
enormous successes in problems previously thought to be beyond the scope of traditional computation.
%
For instance, the recognition of objects in computer vision 
has progressed below human error-rates (for example the ImageNet competition, top-5 error rates
have fallen from 27\% in 2010 to less than 4\% in \cite{MSRresnet}, where human-level performance is around 5\%).

Techniques from Deep Learning are now being applied with a surprising 
level of success to such things as 
image tracking (Denil et al, \cite{VisualAttention}), 
speech recognition (Chorowski et al, \cite{SpeechAttention}), 
language translation (Bahdanau et al, \cite{TranslationAttention}) 
and image captioning (Xu et al, \cite{ImageCaptioning}).
%
One common feature of these techniques is that
the focus of the algorithm's attention is being determined 
(either as a direct aim, or as a side-effect), 
and can be examined in conjunction with the other outputs being produced - 
such as the text being heard, or the objects in the images being recognised.

%Attention mechanisms replacing state-transfer in LSTMs

%Questions about image (or text) can be examined using their map of attention too

%Captioning indicates that `internal process' could be converted into prose

In addition to these explicit attention models, effective language translation
engines have been built (Sutskever et al, \cite{SequenceToSequence}) that reduce
input sentences to a complex `internal state' that can then be further processed into
output prose.  The same `backend' can be applied to the output of image recognition
systems to produce captions too (Karpathy \& Fei-Fei, \cite{karpathy2014deep}).
%
This suggests that it should be possible to expose the inner workings of 
a complex system in (for instance) prose, if required - and, potentially,
introspect on that stream of text too.


% https://github.com/farizrahman4u/seq2seq

% Chatbot systems are pretty rudimentary
% https://www.chatbots.org/ai_zone/viewthread/2153/

In terms of modelling the attention of an outside party, the clearest 
example is in game-play (the most exciting recent instance being Silver et al, \cite{AlphaGo}).
%
However, this is hardly the kind of Other Model that is contemplated in
the Attention Schema theory, since the pure adversarial relationship given in 
this case can be hugely simplified by using a rationality assumption and \emph{minimax}.

%Even with more complex/hidden state-spaces (such as Poker), the degree to which 
%an Other Model needs to incorporate an accurate


%Reinforcement learning sucesses have required the bulding of a model
%of the opponent - although this is simplified by the assumption of mini-max actions

%  Hidden state complicate this - though there still are (?) optimal strategies, even in the face of uncertainty

%Building a model of another actor is now becoming (?) a necessasary feature of chatbot 

%Self-image can be built on same basis


Beyond games, the clearest example of machine-human interaction where having an Other Model
would be beneficial is in the area of chatbots, where conversations often occur in which the 
themes are built up from sentence fragments; the human partner may not
write particularly clearly; and (as internet-facing bots discover) partners
may behave in an adversarial fashion.


% \section{Models : Self and Other}

\section{Practicalities}

%Just as the ImageNet competitions have spurred competitive advances in vision systems, 

Assuming that Attention Schema is a workable framework for awareness,
the process of building a machine with actual consciousness boils down
to successively improving how a machine builds Other Models, 
followed by turning the machine's model builder onto its own behaviour,
so as to build an integrated Self Model.

A natural setting for requiring Other Models is in the context of chatbots,
for which it should be possible to create a number of benchmark conversations 
from which the quality of a machine Other Model mechanism can be determined.  
Ideally, this could be an open competition (qv ImageNet).

Over time, a range of both Other and Self Models could be created, 
and the quality of a given machine's internal monologue could be assessed objectively.
These callibrated consciousnesses could then be used according to their application.


\section{Discussion}

As described above (and assuming that the Attention Schema theory
is as effective as hoped), there are several consequences that should
be pointed out:

\begin{description}

\item[Human-Scale] - any schema being built will not necessarily
benefit from being `super-human', since its basic function is to relate to
humans in human terms (and might be better measured in terms of `Emotional intelligence' - 
Salovey et al, \cite{EmotionalIntelligence}).
%
Indeed, one can imagine that machines having an `internal dialogue' could
quickly become entirely commonplace - since it's nothing out of the ordinary, 
given that every normal human already experiences it for themselves.

\item[Pause/Resume] - since the schema processing would be interpretable
in non-mystical terms, a consciousness that can be paused, backed-up and resumed 
can be handled more pragmatically than a human one that doesn't benefit from these
operations.  
%
Of course, deleting an operating Self Model may require safeguards, such as obtaining
consent, but those are questions of a different kind.

\item[Not Peak AGI] - other dimensions of AGI are likely to be more challenging.
Take, for example, self-improvement : A human having consciousness doesn't 
give them any special knowledge about how to enhance their own neural pathways.
Their sense of self is almost of no consequence to their actual brain operations.
The Attention Schema is simply a model of what is going on, not the processing
itself. 

\item[Multiple Models] - machines could benefit from being able to maintain
more Other Models simultaneously than a human can.  A simple demonstration of 
human limitations is to imagine (for instance) someone else being \emph{elated}.  
It is natural not to be able to do this purely objectively : the human brain 
appears to `time-share' its emotional hardware, so that other people's perceived 
emotional states creep into our own consciousness.

\item[Relatability] - humans are very social animals, and look to form 
social bonds even with non-sentient animals/machines.  For example, 
there was a noticable shift in the way people related to AlphaGo's strategy 
once they understood that it was motivated by win-probability only.
Having a glimpse into it's internal mindset gave commentators a way to 
relate to the machine, which they appeared to find reassuring.


\end{description}

%Callibrated consciousness
%  Based on realism of models of 'other'
%  Depth of introspection can be naturally limited / ascertained
  
%  Ability to pause/save/restart 'self'
%  Might simplify questions of 'rights'

%Self image could also include honest description of differences from humans
%  including an acceptance of being self-contained (and paused, etc)

%Empathy due to time-sharing of mental machinery in order to step into someone else's shoes

%Lower hurdle than self-improving AGIs
%  No need to create novelty in decision-making policy, for instance
  


%Turing test involves convincing a human that a machine should be accredited with conciousness
%  Which is a lower bar than that the machine actually has conciousness
%  OTOH, if the workings of the machine can be fully analysed, many humans would reject the machine's consciousness because it appears insufficient

%The machine reporting on it's own consciousness would lie on a spectrum from lying to honest to super-honest, 
%  depending on the sophistication of its self mental model (and its capacity to model others could be measured)
%  Potentially, the 'other' models could be more sophisticated than human ones
  
%Self-model should be 'relateable' in human terms to aid recognition 
  
    


%https://aeon.co/essays/can-we-make-consciousness-into-an-engineering-problem ::

%We know that, but it doesn't. It possesses no information about how it was built. 
%Its internal models don't contain the information: ``By the way, we're a computing device that 
%accesses internal models, and our models are incomplete and inaccurate.''
%It's not even in a position to report that it has internal models, or that it's processing information at all.
 
%The machine is captive to its internal models, so it can't arrive at any other conclusions.


\section{Conclusions}

%Contributions
%
%	Map current state-of-the-art to components of the Attention Schema theory
%
%	Describe how clarity of this mechanism allows for pause/restore
%
%	Point out the gap between requiring consciousness and (beyond) self-direction towards improvement

The Attention Schema theory is a very interesting framework for 
systematically building the components required for machines with awareness.

Open competitions and benchmarks for chatbot interaction would be 
an effective method to encourage research into developing the necessary 
models of attention / motivations, which might then be re-purposed as Self Models.

Giving machines a positive element of empathy has little bearing on 
them being able to acheive super-human levels of performance on other tasks.
%
Even if the Self Model aspect proves more difficult than is hoped, 
advances in the modelling of human participants in conversations will
be beneficial to chatbot implementations.  




%
% ---- Bibliography ----
%
\begin{thebibliography}{}
%
% Fix the tilde...
\newcommand{\mytilde}{\raise.17ex\hbox{$\scriptstyle\mathtt{\sim}$}}

%\bibitem[2012]{Joscha-Bach-2012-interview}
%Bach, Joscha:
%AGI 2012 Interview.
%(https://youtu.be/PyKzO0MF1zI?t=12m36s)

\bibitem[2014]{Bengio-et-al-2014-Book}
%Bengio, Yoshua; Goodfellow, Ian J. and Courville, Aaron:
%Deep Learning.
%% http://www.iro.umontreal.ca/~bengioy/dlbook/disentangling.html
%(http://www.iro.umontreal.ca/\mytilde{}bengioy/dlbook)
%MIT Press (2014, in prep.)

%\bibitem[2014]{PCAnet}
%Tsung-Han Chan; Kui Jia; Shenghua Gao; Jiwen Lu; Zinan Zeng; Yi Ma:
%PCANet: A Simple Deep Learning Baseline for Image Classification?
%arXiv:1404.3606v2 (2014)

%\bibitem[2013]{bengio-whitening}
%G{\"u}l{\c{c}}ehre, {\c{C}}a{\u{g}}lar and Bengio, Yoshua:
%Knowledge matters: Importance of prior information for optimization.
%CoRR, abs/1301.4083 (2013)

%\bibitem[2009]{norvig-UnreasonableEffectivenessOfData}
%Halevy, Alon; Norvig, Peter and Pereira, Fernando:
%The Unreasonable Effectiveness of Data.
%IEEE Intelligent Systems, vol. 24, pp. 8-12 (2009)

%\bibitem[1997]{harpur-thesis}
%Harpur, George Francis: 
%Low entropy coding with unsupervised neural networks.
%Dissertation, University of Cambridge (1997)

%\bibitem[2012]{hinton-dropout}
%Hinton, Geoffrey E; Srivastava, Nitish; Krizhevsky, Alex; Sutskever, Ilya and Salakhutdinov, Ruslan R:
%Improving neural networks by preventing co-adaptation of feature detectors.
%arXiv:1207.0580 (2012)

%\bibitem[2015]{WhiteningOfData}
%Ioffe, Sergey and Szegedy, Christian:
%Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.
%arXiv:1502.03167v3 (2015)

%\bibitem[2014]{Lillicrap-random-matrix}
%Lillicrap, Timothy P.; Cownden, Daniel; Tweed, Douglas B. and Akerman, Colin J.:
%Random feedback weights support learning in deep neural networks.
%arXiv:1411.0247 (2014)

\bibitem[2011]{GrazianoKastner}
Michael S. A.   Graziano  and  Sabine   Kastner:
Awareness as a Perceptual Model of Attention.
Cognitive Neuroscience (2011), vol 2, no. 2, pp 125--127


\bibitem[2013]{graziano2013consciousness}
Graziano, Michael SA:
Consciousness and the Social Brain.
Oxford University Press, 2014


%\bibitem[2015]{MSRimagenet}
%He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian
%Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification
%arXiv:1502.01852 (2015)

\bibitem[2014]{SchmidhuberOverview}
Schmidhuber, J{\"u}rgen:
Deep Learning in Neural Networks: An Overview.
arXiv:1404.7828v4 (2014)


\bibitem[2015]{MSRresnet}
He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian:
Deep Residual Learning for Image Recognition.
arXiv:1512.03385 (2015)


\bibitem[2011]{VisualAttention}
{Denil}, M. and {Bazzani}, L. and {Larochelle}, H. and {de Freitas}, N.:
Learning where to Attend with Deep Architectures for Image Tracking.
arXiv:1109.3737 (2011)

\bibitem[2015]{SpeechAttention}
{Chorowski}, J. and {Bahdanau}, D. and {Serdyuk}, D. and {Cho}, K. and {Bengio}, Y.:
Attention-Based Models for Speech Recognition.
arXiv:1506.07503 (2015)


\bibitem[2014]{TranslationAttention}
{Bahdanau}, D. and {Cho}, K. and {Bengio}, Y.:
Neural Machine Translation by Jointly Learning to Align and Translate.
arXiv:1409.0473 (2014)



\bibitem[2015]{ImageCaptioning}
{Xu}, K. and {Ba}, J. and {Kiros}, R. and {Cho}, K. and {Courville}, A. and {Salakhutdinov}, R. and {Zemel}, R. and {Bengio}, Y.:
Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.
arXiv:1502.03044 (2015)


\bibitem[2015]{SequenceToSequence}
{Sutskever}, I. and {Vinyals}, O. and {Le}, Q.~V.:
Sequence to Sequence Learning with Neural Networks.
arXiv:1409.3215 (2014)

\bibitem[2014]{karpathy2014deep}
Karpathy, Andrej and Fei-Fei, Li:
Deep visual-semantic alignments for generating image descriptions.
arXiv:1412.2306 (2014)



\bibitem[2016]{AlphaGo}
Silver, D et al:
Mastering the Game of Go with Deep Neural Networks and Tree Search.
Nature (2016), vol 529, pp 484--503


\bibitem[2004]{EmotionalIntelligence}
Salovey, Peter; Mayer, John; Caruso, David:
Emotional Intelligence: Theory, Findings, and Implications.
Psychological Inquiry, pp. 197–215


\end{thebibliography}

\end{document}


