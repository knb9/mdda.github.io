% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%  
\documentclass[citeauthoryear]{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
%
\begin{document}
%
\frontmatter          % for the preliminaries
%
\pagestyle{headings}  % switches on printing of running heads
\addtocmark{Lessons from Deep Learning} % additional mark in the TOC
%
\mainmatter              % start of the contributions
%
\title{Lessons from Deep Learning}
%
\titlerunning{Lessons from Deep Learning}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Martin Andrews\inst{1}}
%
\authorrunning{Martin Andrews} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
\tocauthor{Martin Andrews}
%
\institute{Red Cat Labs, Singapore, \\
\email{Martin.Andrews@RedCatLabs.com},\\ 
WWW home page: \texttt{http://RedCatLabs.com/}
}

\maketitle              % typeset the title of the contribution

%%%% using at least 70 and at most 150 words. It will be set in 9-point
\begin{abstract}
%In an interview \cite{Joscha-Bach-2012-interview} during AGI 2012, Joscha Bach made an interesting comment that 
%the process of achieving AGI will likely require the discovery of its `100 organizational principles'.
%Those principles may be obvious in hindsight, but (using the example of Backpropagation learning)
%may take a long time for mankind to discover.
%This short communication outlines a few more candidate building blocks to put on the list, 
%while discussing which apects of Backpropagation mean that it deserves to be included.  

%The complexity of each organizational principle might be of the order of Backpropagation learning - 

%  What deep learning can tell us about finding organizational principles

In an interview during AGI \cite{Joscha-Bach-2012-interview}, Joscha Bach
made an interesting comment that the process of achieving 
AGI will likely require the discovery of `100 organizational principles' - 
using Backpropagation learning as an example of the scale of each one of those principles.  

This short paper reflects on the lessons to be learned from 
the recent successes of Deep Learning research and its relevance in terms 
of `the list' of AGI principles.

\keywords{deep learning, backpropagation, AGI organisational principles}
\end{abstract}
%
\section{Background}
% **  What deep learning can tell us about finding organizational principles ** 

Within the Neural Network (NN) field, 
recent advances in Deep Learning demonstrate better-than-human 
levels of perfomance in image classification, 
and dramatic improvements in domains such as speech recognition.  
This short paper reflects on the lessons that can be learned 
from the Deep Learning AI sub-genre, which has had its own `winter' 
since NNs were first fashionable in the 1980s.  

%\section{Overview}
%
%Short "technical communications", with a limit of 4 pages, 
%summarizing results and ideas of interest to the AGI audience, 
%including : 
%  reports about recent publications, 
%  position papers, and 
%  preliminary results.
%
%Appropriate topics for contributed papers include, but are not restricted to:
%  Creativity
%  Knowledge Representation for General Intelligence
%  Learning, and Learning Theory
%  Natural Language Understanding
%  Neural-Symbolic Processing
%  Philosophy of AGI
%  Reinforcement Learning
%
%Submission deadline moved from 15-march-2015 to 1-apr-2015
%  :: http://agi-conf.org/2015/call-for-papers/

\section{Deep Learning Lessons}

Here, for simplicity, the `early days' will refer to the 1980s/early-1990s,
the `new phase' as 2006 onwards, and `recently' to 2011 to the present day
(with much respect to those who founded the field earlier, and also 
those who soldiered on during the in-between times).  
For a comprehensive review of the NN and Deep Learning literature, see Schmidhuber (\cite{SchmidhuberOverview}).
 

\subsubsection*{Did we give up too early?}
 
The reasons being given for the success of the new phase of Deep Learning 
(compared to the early days) is the combination of increased model size and 
vast amounts of training data, using machines that are orders of magnitude faster.  
Considering each of these factors :

\begin{description}

\item[Model size] - in the early days, it was known (Harpur \cite{harpur-thesis}) 
that tractable techniques such as Principal Component Analysis (PCA) could be realised  
through biologically realistic processes, as well as via more efficient (for silicon) numerical implementations.  
Thus, linear-based models would have been tractable then, 
and could serve (even now) as a realistic baseline against which to compare 
more elaborate neural network models (Chan \emph{et al.} \cite{PCAnet}).

\item[Data] - simply having more data available during the `new phase' 
is also a factor\footnote{as is the bravado actually to attempt to train a model on the data to see what happens.}
(The Unreasonable Effectiveness of Data : Halevy, Norvig \& Pereira \cite{norvig-UnreasonableEffectivenessOfData}).

\item[Processing Speed] - this factor would be more convincing if it had been reported at the time 
that the experiments were working, but much too slowly.  
In today's experiments, large (downward) jumps in error are usually experienced in early training epochs.  
These jumps should have been observable in the past 
even if the experiment couldn't have been run to convergence.  

So maybe the reasoning is more nuanced : It is not just the raw learning speed 
for a given experiment that is important, but 
(from a researcher's point of view) the iteration / experiment cycle time.

\end{description}


\subsubsection*{Random Propagation.}

While the basic backpropagation is easily understood as the application 
of the chain rule backwards through the network, it is rarely used in pure form
because various speed-up methods (such as momentum terms, ADAgrad, RMSprop, etc)
are almost a requirement for reasonable training times.  

While some of these methods are grounded in optimisation theory, 
others have been developed by `seeing what works' - and have shown that 
learning occurs even with random matrix error propagation 
(Lillicrap \cite{Lillicrap-random-matrix}).  


\subsubsection*{Exploding gradients.}

The basic operation of a network layer (matrix multiply and non-linearity) 
naturally leads to the problem of `exploding gradients'.
With the new phase of research came techniques that mitigate the problem : 

\begin{description}

\item[Rectified Linear Units (ReLU) layers] - by computing output vectors $y$ 
using the minimalistic computation $y=max(Wx+b, 0)$ neatly avoids 
scaling problems, since the non-linearity is scale-agnostic.

\item[Informed intialisation schemes] - network weights are initialised 
to random values that are scaled based on fan-in/fan-out considerations as a way of making the 
average scaling-factor of the matrix multiplication closer to unity.

\item[Normalization] - the scaling of the layer outputs can be controlled
dynamically (described in G{\"u}l{\c{c}}ehre \& Bengio \cite{bengio-whitening} and 
Ioffe \& Szegedy \cite{WhiteningOfData}).

\end{description}

In retrospect, the fact that simple Genetic Algorithms (GAs) could train 
NNs roughly as quickly as gradient descent during the early days, 
should have been telling : With exact gradients, local search should have 
been much more effective than any global search method.


\subsubsection*{Natural Problems aren't Antagonistic.}

In the early days, NN researchers spent a lot of time on the 
XOR problem, and with self-selected toy problems that were 
intentionally made challenging for networks to learn.

More recently, Deep Learning sucesses have shown that real-world data sets 
are not as antagonistic to being learned as anticipated.  
This might illustrate that the priors embedded in network learning are 
somehow sympathetic to the data being learned 
(see, for instance, `Priors Regarding The Underlying Factors' in Bengio \emph{et al.} \cite{Bengio-et-al-2014-Book}),
or that the interesting features that humans have identified as being 
worth learning are those that `come easily' to human brains.

\subsubsection*{Common Problem Sets.}

Introducing a competitive element into research, by having fully published
training and test sets, has clearly pushed the state-of-the-art along more 
quickly than the previous regime in which interesting data sets were closely held.
The flip side of this is that less time is spent on \emph{understanding}
compared to the discovery of radical ideas and subsequent model refinement.


\section{Deep Learning Discoveries}

The following can all be characterized as `unfairly effective', and have 
arisen as part of the rapid exploration that characterises Deep Learning research.

\subsubsection*{Trailblazing.}
The Deep Learning field appears to encourage new ideas, giving 
practitioners the freedom to attempt the impossible.  
These are sometimes reincorporated into the mainstream once researchers in those 
fields realize that something previously unthinkable actually works.

\subsubsection*{Transfer Learning / Internal Representations.}
Taking a cross-section through a trained network to see its internal representation
has been shown to be applicable to other problem domains (eg: Karpathy \& Fei-Fei, \cite{karpathy2014deep}).

The usefulness of these internal representations\footnote{ 
... which could also be thought of as `ideas', particularly 
if there were a means to capture transitions between them, aka `stories'.}
has powerful implications regarding the power of systems to enhance 
each other's effectiveness without the 
brittleness associated with building a single `monolithic' system.

\subsubsection*{Word Vector Embedding.}
Originally almost a by-product of learning a word-prediction task, a vector 
space can be automatically learned to describe words (given a sufficient
quantity of well-formed sentences in a given langauge, and \emph{zero} linguistic knowledge).
This is both surprising and encouraging for AGI.

\subsubsection*{Convolutional NNs.}
This formulation of NNs started as a trick to usefully capture 
the structural properties of input images.  
However, it was then found that the network layers map (loosely) 
to the different levels of processing within the brain in a way that is highly suggestive 
of having explanatory power.

\subsubsection*{Drop-out.}
This training enhancement (Hinton \emph{et al.} \cite{hinton-dropout}) 
can be rationalised as allowing multiple competitive ensembles to self-organize.  
However, despite the essence of its operation not being fully understood, 
many researchers are using it as part of their standard toolkit without 
exploring why it works.


\section{Other Organisational Principles}

Instead of reiterating points made above (by way of a conclusion), 
it is worth highlighting here a few more organisational principles that 
seem appropriate to suggest for inclusion on `the list' for AGI:

\begin{description}
\item[Evolutionary Methods] - currently appear to be suffering through 
a winter of its own, despite working `unfairly well'.
\item[Ensemble Methods] - whereby an ensemble of different approaches to 
solving a problem to rise above the accuracy 
of any one method has a simple mathematical underpinning.  
\item[Sparse Encodings] - relatively unexplored compared to the use that 
the brain appears to make of them (note that Sparse PCA, while interesting, 
may be optimising for the `final layer' rather than useful intermediate steps).
\item[Minimum Description Length] - a concept-cluster that extends from compression, 
to information theory, encompassing Occam's razor along the way.
\end{description}

%\section{Conclusions}

%
% ---- Bibliography ----
%
\begin{thebibliography}{}
%
% Fix the tilde...
\newcommand{\mytilde}{\raise.17ex\hbox{$\scriptstyle\mathtt{\sim}$}}

\bibitem[2012]{Joscha-Bach-2012-interview}
Bach, Joscha:
AGI 2012 Interview.
(https://youtu.be/PyKzO0MF1zI?t=12m36s)

\bibitem[2014]{Bengio-et-al-2014-Book}
Bengio, Yoshua; Goodfellow, Ian J. and Courville, Aaron:
Deep Learning.
% http://www.iro.umontreal.ca/~bengioy/dlbook/disentangling.html
(http://www.iro.umontreal.ca/\mytilde{}bengioy/dlbook)
MIT Press (2014, in prep.)

\bibitem[2014]{PCAnet}
Tsung-Han Chan; Kui Jia; Shenghua Gao; Jiwen Lu; Zinan Zeng; Yi Ma:
PCANet: A Simple Deep Learning Baseline for Image Classification?
arXiv:1404.3606v2 (2014)

\bibitem[2013]{bengio-whitening}
G{\"u}l{\c{c}}ehre, {\c{C}}a{\u{g}}lar and Bengio, Yoshua:
Knowledge matters: Importance of prior information for optimization.
CoRR, abs/1301.4083 (2013)

\bibitem[2009]{norvig-UnreasonableEffectivenessOfData}
Halevy, Alon; Norvig, Peter and Pereira, Fernando:
The Unreasonable Effectiveness of Data.
IEEE Intelligent Systems, vol. 24, pp. 8-12 (2009)

\bibitem[1997]{harpur-thesis}
Harpur, George Francis: 
Low entropy coding with unsupervised neural networks.
Dissertation, University of Cambridge (1997)

\bibitem[2012]{hinton-dropout}
Hinton, Geoffrey E; Srivastava, Nitish; Krizhevsky, Alex; Sutskever, Ilya and Salakhutdinov, Ruslan R:
Improving neural networks by preventing co-adaptation of feature detectors.
arXiv:1207.0580 (2012)

\bibitem[2015]{WhiteningOfData}
Ioffe, Sergey and Szegedy, Christian:
Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.
arXiv:1502.03167v3 (2015)

\bibitem[2014]{karpathy2014deep}
Karpathy, Andrej and Fei-Fei, Li:
Deep visual-semantic alignments for generating image descriptions.
arXiv:1412.2306 (2014)

\bibitem[2014]{Lillicrap-random-matrix}
Lillicrap, Timothy P.; Cownden, Daniel; Tweed, Douglas B. and Akerman, Colin J.:
Random feedback weights support learning in deep neural networks.
arXiv:1411.0247 (2014)

\bibitem[2014]{SchmidhuberOverview}
Schmidhuber, J{\"u}rgen:
Deep Learning in Neural Networks: An Overview.
arXiv:1404.7828v4 (2014)


\end{thebibliography}

\end{document}


